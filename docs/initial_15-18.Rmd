---
title: "Initial 2015-2018 Data Creation"
author: "Christopher Prener, Ph.D."
date: '(`r format(Sys.time(), "%B %d, %Y")`)'
output: 
  github_document: default
  html_notebook: default 
---

## Introduction
This notebook contains the initial code for cleaning the 2015-2018 crime file data to create Shaw-specific shapefiles.

## Dependencies
This notebook requires:

```{r load-packages}
# primary data tools
library(compstatr)     # work with stlmpd crime data

# tidyverse packages
library(dplyr)         # data wrangling
library(readr)         # working with csv data

# spatial packages
library(sf)            # working with spatial data
library(tidycensus)
library(tigris)        # tiger/line api access

# other packages
library(janitor)       # frequency tables
library(here)          # file path management
library(knitr)         # output
library(testthat)      # unit testing
```

## Create Data
Data downloaded from the STLMPD website come in `.csv` format but with the wrong file extension. The following bash script copies them to a new subdirectory and fixes the file extension issue:

```{bash}
# change working directory
cd ..
# execute cleaning script
bash source/reformatHTML.sh
```

## Load Data
With our data renamed, we build a year list objects for 2016, 2017, and 2018 crimes:

```{r load-data}
data2015 <- cs_load_year(here("data", "intermediate", "2015"))
data2016 <- cs_load_year(here("data", "intermediate", "2016"))
data2017 <- cs_load_year(here("data", "intermediate", "2017"))
data2018 <- cs_load_year(here("data", "intermediate", "2018"))
```

## Validate Data
### 2015
Next we make sure there are no problems with the crime files in terms of incongruent columns for 2015:

```{r validate-data15}
cs_validate_year(data2015, year = "2015")
```

We can use the `verbose = TRUE` option on `cs_validate_year()` to identify areas where the validation checks have failed:

```{r validate-data15-v}
cs_validate_year(data2015, year = "2015", verbose = TRUE)
```

Since thhere are only issues with the class validation, we're going to consider these validated for now.

### 2015
We'll repeat the same validation for 2016:

```{r validate-data16}
cs_validate_year(data2016, year = "2016")
```

We can use the `verbose = TRUE` option on `cs_validate_year()` to identify areas where the validation checks have failed:

```{r validate-data16-v}
cs_validate_year(data2016, year = "2016", verbose = TRUE)
```

Since thhere are only issues with the class validation, we're going to consider these validated for now.

### 2017

All of the data passes the validation checks.

```{r validate-data17}
cs_validate_year(data2017, year = "2017")
```

We can use the `verbose = TRUE` option on `cs_validate_year()` to identify areas where the validation checks have failed:

```{r validate-data17-v}
cs_validate_year(data2017, year = "2017", verbose = TRUE)
```

The data for May 2017 do not pass the validation checks. We can extract this month and confirm that there are too many columns in the May 2017 release. Once we have that confirmed, we can standardize that month and re-run our validation.

```{r fix-may-cols}
# extract data
may2017 <- cs_extract_month(data2017, month = "May")
# unit test column number
expect_equal(ncol(may2017), 26)
# remove object
rm(may2017)
# standardize months
data2017 <- cs_standardize(data2017, month = "May", config = 26)
# validate data
cs_validate_year(data2017, year = "2017")
```

We still get a `FALSE` value for `cs_validate_year()`:

```{r validate-data17-v2}
cs_validate_year(data2017, year = "2017", verbose = TRUE)
```

We've now limited the validation issues to the classes.

### 2018
Finally, we'll attempt to validate the 2018 data:

```{r validate-data18}
cs_validate_year(data2018, year = "2018")
```

Now with the `verbose = TRUE` option:

```{r validate-data18-v}
cs_validate_year(data2018, year = "2018", verbose = TRUE)
```

## Collapse Data
With the data validated, we collapse each year into a single, flat object:

```{r collapse-data}
data2015_flat <- cs_collapse(data2015)
data2016_flat <- cs_collapse(data2016)
data2017_flat <- cs_collapse(data2017)
data2018_flat <- cs_collapse(data2018)
```

What we need for this project is a single object with only the crimes for 2016. Since crimes were *reported* in subsequent years for 2015 (as well as 2016 and 2017), we need to merge all the tables and then retain only the relevant year's data. The `cs_combine()` function will do this:

```{r combine-data}
crimes2015 <- cs_combine(type = "year", date = 2015, data2015_flat, data2016_flat, data2017_flat, data2018_flat)
crimes2016 <- cs_combine(type = "year", date = 2016, data2016_flat, data2017_flat, data2018_flat)
crimes2017 <- cs_combine(type = "year", date = 2017, data2017_flat, data2018_flat)
crimes2018 <- cs_combine(type = "year", date = 2018, data2018_flat)
```

### Clean-up Enviornment
With our data created, we can remove some of the intermediary objects we've created:

```{r rm-initial-objects}
rm(data2015, data2015_flat, data2016, data2016_flat, data2017, data2017_flat, data2018, data2018_flat)
```

## Remove Unfounded Crimes and Subset Based on Type of Crime:
The following code chunk removes unfounded crimes (those where `Count == -1`) and then creates a data frame for all part one crimes for each year. We also print the number of crimes missing spatial data. In general, these tend to be rapes.

### 2015

```{r subset-data-15}
crimes2015 %>% 
  cs_filter_count(var = Count) %>%
  cs_filter_crime(var = Crime, crime = "Part 1") %>%
  cs_crime_cat(var = Crime, newVar = crimeCat, output = "string") %>%
  cs_missing_xy(varx = XCoord, vary = YCoord, newVar = xyStatus) %>%
  select(Complaint, DateOccur, Crime, crimeCat, District, Description, 
         ILEADSAddress, ILEADSStreet, XCoord, YCoord, xyStatus) -> p1_2015

p1_2015 %>%
  tabyl(xyStatus) %>%
  adorn_pct_formatting(digits = 3) %>%
  kable()
```

```{r table-crimeCat-2015}
p1_2015 %>%
  tabyl(crimeCat) %>%
  adorn_pct_formatting(digits = 3) %>%
  kable()
```

### 2016

```{r subset-data-16}
crimes2016 %>% 
  cs_filter_count(var = Count) %>%
  cs_filter_crime(var = Crime, crime = "Part 1") %>%
  cs_crime_cat(var = Crime, newVar = crimeCat, output = "string") %>%
  cs_missing_xy(varx = XCoord, vary = YCoord, newVar = xyStatus) %>%
  select(Complaint, DateOccur, Crime, crimeCat, District, Description, 
         ILEADSAddress, ILEADSStreet, XCoord, YCoord, xyStatus) -> p1_2016

p1_2016 %>%
  tabyl(xyStatus) %>%
  adorn_pct_formatting(digits = 3) %>%
  kable()
```


```{r table-crimeCat-2016}
p1_2016 %>%
  tabyl(crimeCat) %>%
  adorn_pct_formatting(digits = 3) %>%
  kable()
```


### 2017

```{r subset-data-17}
crimes2017 %>% 
  cs_filter_count(var = Count) %>%
  cs_filter_crime(var = Crime, crime = "Part 1") %>%
  cs_crime_cat(var = Crime, newVar = crimeCat, output = "string") %>%
  cs_missing_xy(varx = XCoord, vary = YCoord, newVar = xyStatus) %>%
  select(Complaint, DateOccur, Crime, crimeCat, District, Description, 
         ILEADSAddress, ILEADSStreet, XCoord, YCoord, xyStatus) -> p1_2017

p1_2017 %>%
  tabyl(xyStatus) %>%
  adorn_pct_formatting(digits = 3) %>%
  kable()
```

```{r table-crimeCat-2017}
p1_2017 %>%
  tabyl(crimeCat) %>%
  adorn_pct_formatting(digits = 3) %>%
  kable()
```

### 2018

```{r subset-data-18}
crimes2018 %>% 
  cs_filter_count(var = Count) %>%
  cs_filter_crime(var = Crime, crime = "Part 1") %>%
  cs_crime_cat(var = Crime, newVar = crimeCat, output = "string") %>%
  cs_missing_xy(varx = XCoord, vary = YCoord, newVar = xyStatus) %>%
  select(Complaint, DateOccur, Crime, crimeCat, District, Description, 
         ILEADSAddress, ILEADSStreet, XCoord, YCoord, xyStatus) -> p1_2018

p1_2018 %>%
  tabyl(xyStatus) %>%
  adorn_pct_formatting(digits = 3) %>%
  kable()
```

```{r table-crimeCat-2018}
p1_2018 %>%
  tabyl(crimeCat) %>%
  adorn_pct_formatting(digits = 3) %>%
  kable()
```

## Clean Enviornment

```{r}
rm(crimes2015, crimes2016, crimes2017, crimes2018)
```

## Create Violent Crime Data Frames

```{r}
vc_2015 <- cs_filter_crime(p1_2015, var = Crime, crime = "violent")
vc_2016 <- cs_filter_crime(p1_2016, var = Crime, crime = "violent")
vc_2017 <- cs_filter_crime(p1_2017, var = Crime, crime = "violent")
vc_2018 <- cs_filter_crime(p1_2018, var = Crime, crime = "violent")
```

## Project Data
We project the main set of previously geocoded data, remove excess columns, and transform the data to NAD 1983:

```{r project-valid}
p1_2015 %>%
  st_as_sf(coords = c("XCoord", "YCoord"), crs = 102696) %>%
  select(-xyStatus) %>%
  st_transform(crs = 4269) -> p1_2015

p1_2016 %>%
  st_as_sf(coords = c("XCoord", "YCoord"), crs = 102696) %>%
  select(-xyStatus) %>%
  st_transform(crs = 4269) -> p1_2016

p1_2017 %>%
  st_as_sf(coords = c("XCoord", "YCoord"), crs = 102696) %>%
  select(-xyStatus) %>%
  st_transform(crs = 4269) -> p1_2017

p1_2018 %>%
  st_as_sf(coords = c("XCoord", "YCoord"), crs = 102696) %>%
  select(-xyStatus) %>%
  st_transform(crs = 4269) -> p1_2018

vc_2015 %>%
  st_as_sf(coords = c("XCoord", "YCoord"), crs = 102696) %>%
  select(-xyStatus) %>%
  st_transform(crs = 4269) -> vc_2015

vc_2016 %>%
  st_as_sf(coords = c("XCoord", "YCoord"), crs = 102696) %>%
  select(-xyStatus) %>%
  st_transform(crs = 4269) -> vc_2016

vc_2017 %>%
  st_as_sf(coords = c("XCoord", "YCoord"), crs = 102696) %>%
  select(-xyStatus) %>%
  st_transform(crs = 4269) -> vc_2017

vc_2018 %>%
  st_as_sf(coords = c("XCoord", "YCoord"), crs = 102696) %>%
  select(-xyStatus) %>%
  st_transform(crs = 4269) -> vc_2018
```

## Spatial Join with Neighborhood Data

```{r}
st_read(here("data", "raw", "nhood", "STL_BOUNDARY_Nhoods.shp"), stringsAsFactors = FALSE) %>%
  st_transform(crs = 102696) -> nhoods

nhoods %>%
  filter(NHD_NAME == "Shaw") %>%
  select(NHD_NUM, NHD_NAME) -> shaw

rm(nhoods)
```

```{r}
p1_2015 %>%
  st_transform(crs = 102696) %>%
  st_intersection(., shaw) %>%
  st_transform(crs = 4269) %>%
  select(-NHD_NAME, -NHD_NUM) -> p1_2015_shaw

p1_2016 %>%
  st_transform(crs = 102696) %>%
  st_intersection(., shaw) %>%
  st_transform(crs = 4269) %>%
  select(-NHD_NAME, -NHD_NUM) -> p1_2016_shaw

p1_2017 %>%
  st_transform(crs = 102696) %>%
  st_intersection(., shaw) %>%
  st_transform(crs = 4269) %>%
  select(-NHD_NAME, -NHD_NUM) -> p1_2017_shaw

p1_2018 %>%
  st_transform(crs = 102696) %>%
  st_intersection(., shaw) %>%
  st_transform(crs = 4269) %>%
  select(-NHD_NAME, -NHD_NUM) -> p1_2018_shaw

vc_2015 %>%
  st_transform(crs = 102696) %>%
  st_intersection(., shaw) %>%
  st_transform(crs = 4269) %>%
  select(-NHD_NAME, -NHD_NUM) -> vc_2015_shaw

vc_2016 %>%
  st_transform(crs = 102696) %>%
  st_intersection(., shaw) %>%
  st_transform(crs = 4269) %>%
  select(-NHD_NAME, -NHD_NUM) -> vc_2016_shaw

vc_2017 %>%
  st_transform(crs = 102696) %>%
  st_intersection(., shaw) %>%
  st_transform(crs = 4269) %>%
  select(-NHD_NAME, -NHD_NUM) -> vc_2017_shaw

vc_2018 %>%
  st_transform(crs = 102696) %>%
  st_intersection(., shaw) %>%
  st_transform(crs = 4269) %>%
  select(-NHD_NAME, -NHD_NUM) -> vc_2018_shaw
```

## Write Shapefiles

```{r}
st_write(p1_2015_shaw, here("data", "clean", "Part 1", "2015", "SHAW_Part1_2015.shp"), delete_dsn = TRUE)
st_write(p1_2016_shaw, here("data", "clean", "Part 1", "2016", "SHAW_Part1_2016.shp"), delete_dsn = TRUE)
st_write(p1_2017_shaw, here("data", "clean", "Part 1", "2017", "SHAW_Part1_2017.shp"), delete_dsn = TRUE)
st_write(p1_2018_shaw, here("data", "clean", "Part 1", "2018", "SHAW_Part1_2018.shp"), delete_dsn = TRUE)
st_write(vc_2015_shaw, here("data", "clean", "Violent", "2015", "SHAW_Violent_2015.shp"), delete_dsn = TRUE)
st_write(vc_2016_shaw, here("data", "clean", "Violent", "2016", "SHAW_Violent_2016.shp"), delete_dsn = TRUE)
st_write(vc_2017_shaw, here("data", "clean", "Violent", "2017", "SHAW_Violent_2017.shp"), delete_dsn = TRUE)
st_write(vc_2018_shaw, here("data", "clean", "Violent", "2018", "SHAW_Violent_2018.shp"), delete_dsn = TRUE)
st_write(shaw, here("data", "clean", "Shaw", "SHAW_Boundary.shp"), delete_dsn = TRUE)
```

## Crime Rates

```{r}
years <- c(2015, 2016, 2017)

years %>%
  unlist(years) %>%
  purrr:::map_df(~ get_acs(year = .x, geography = "county", variable = "B01003_001", state = 29, county = 510)) -> cityPop

tract15 <- get_acs(year = 2015, geography = "tract", variable = "B01003_001", 
                        state = 29, county = 510)

tract16 <- get_acs(year = 2016, geography = "tract", variable = "B01003_001", 
                        state = 29, county = 510)

tract17 <- get_acs(year = 2017, geography = "tract", variable = "B01003_001", 
                        state = 29, county = 510)

tracts <- tigris::tracts(state = 29, count = 510, class = "sf")
tracts <- select(tracts, GEOID)

tract15 <- left_join(tracts, tract15, by = "GEOID")
tract15 <- st_transform(tract15, crs = 102696)

tract16 <- left_join(tracts, tract16, by = "GEOID")
tract16 <- st_transform(tract16, crs = 102696)

tract17 <- left_join(tracts, tract17, by = "GEOID")
tract17 <- st_transform(tract17, crs = 102696)

rm(tracts)
```


```{r}
shaw15 <- areal::aw_interpolate(shaw, tid = NHD_NUM, source = tract15, sid = GEOID, 
                      weight = "total", output = "tibble", extensive = "estimate")

shaw16 <- areal::aw_interpolate(shaw, tid = NHD_NUM, source = tract16, sid = GEOID, 
                      weight = "total", output = "tibble", extensive = "estimate")

shaw17 <- areal::aw_interpolate(shaw, tid = NHD_NUM, source = tract17, sid = GEOID, 
                      weight = "total", output = "tibble", extensive = "estimate")

rm(tract15, tract16, tract17)
```


```{r}
murder_2015 <- filter(vc_2015, crimeCat == "Homicide")
murder_2016 <- filter(vc_2016, crimeCat == "Homicide")
murder_2017 <- filter(vc_2017, crimeCat == "Homicide")
murder_2018 <- filter(vc_2018, crimeCat == "Homicide")

murder_2015_shaw <- filter(vc_2015_shaw, crimeCat == "Homicide")
murder_2016_shaw <- filter(vc_2016_shaw, crimeCat == "Homicide")
murder_2017_shaw <- filter(vc_2017_shaw, crimeCat == "Homicide")
murder_2018_shaw <- filter(vc_2018_shaw, crimeCat == "Homicide")
```

```{r}
cityCrime <- data.frame(
  year = c(2015, 2016, 2017, 2018),
  pop = c(cityPop$estimate[1], cityPop$estimate[2], cityPop$estimate[3], cityPop$estimate[3]),
  homicideCount = c(nrow(murder_2015), nrow(murder_2016), nrow(murder_2017), nrow(murder_2018)),
  vcCount = c(nrow(vc_2015), nrow(vc_2016), nrow(vc_2017), nrow(vc_2018)),
  p1Count = c(nrow(p1_2015), nrow(p1_2016), nrow(p1_2017), nrow(p1_2018)),
  stringsAsFactors = FALSE
)

cityCrime %>%
  mutate(city_homicideRate = (homicideCount/pop)*100000) %>%
  mutate(city_vcRate = (vcCount/pop)*100000) %>%
  mutate(city_p1Rate = (p1Count/pop)*100000) -> cityCrime

shawCrime <- data.frame(
  year = c(2015, 2016, 2017, 2018),
  pop = c(shaw15$estimate, shaw16$estimate, shaw17$estimate, shaw17$estimate),
  homicideCount = c(nrow(murder_2015_shaw), nrow(murder_2016_shaw), nrow(murder_2017_shaw), nrow(murder_2018_shaw)),
  vcCount = c(nrow(vc_2015_shaw), nrow(vc_2016_shaw), nrow(vc_2017_shaw), nrow(vc_2018_shaw)),
  p1Count = c(nrow(p1_2015_shaw), nrow(p1_2016_shaw), nrow(p1_2017_shaw), nrow(p1_2018_shaw)),
  stringsAsFactors = FALSE
)

shawCrime %>%
  mutate(homicideRate = (homicideCount/pop)*100000) %>%
  mutate(vcRate = (vcCount/pop)*100000) %>%
  mutate(p1Rate = (p1Count/pop)*100000) -> shawCrime

cityCrime %>%
  select(year, city_homicideRate, city_vcRate, city_p1Rate) %>%
  left_join(shawCrime, ., by = "year") %>%
  mutate(homicideRatio = homicideRate/city_homicideRate) %>%
  mutate(vcRatio = vcRate/city_vcRate) %>%
  mutate(p1Ratio = p1Rate/city_p1Rate) %>%
  select(year, pop, 
         homicideCount, homicideRate, city_homicideRate, homicideRatio,
         vcCount, vcRate, city_vcRate, vcRatio,
         p1Count, p1Rate, city_p1Rate, p1Ratio) -> shawCrime

write_csv(shawCrime, path = here("data", "clean", "shawCrime.csv"))
```


